---
title: 'NORM_COL 1 - Data set: CUPS'
output:
  pdf_document: default
  html_document: default
  word_document: default
  editor_options:
    chunk_output_type: console
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## INTRODUZIONE

Il data set contiene performance di misura e caratteristiche di 209 CPUs. Le variabili sono le seguenti:

1. NAME: produttore del modello
2. SYCT: cycle time in nanosecondi
3. MMIN: minimim main memory in KB
4. MMAX: maximum main memory in KB
5. CACH: cache size in KB
6. CHMIN: minimum number of channels
7. CHMAX: maximum number of channels
8. PERF: performance della CPU comparata con il modello IBM 370/158-3
9. ESTPERF: stima della performance

Analisi proposte:

1. Statistiche descrittive
2. Regressione lineare

> >

```{r,eval=TRUE,echo=T,warning=FALSE,message=F,results="asis"}
#-- R CODE

library(pander)
library(car)
library(olsrr)
library(systemfit)
library(het.test)
panderOptions('knitr.auto.asis', FALSE)

#-- White test function
white.test <- function(lmod,data=d){
  u2 <- lmod$residuals^2
  y <- fitted(lmod)
  Ru2 <- summary(lm(u2 ~ y + I(y^2)))$r.squared
  LM <- nrow(data)*Ru2
  p.value <- 1-pchisq(LM, 2)
  data.frame("Test statistic"=LM,"P value"=p.value)
}

#-- funzione per ottenere osservazioni outlier univariate
FIND_EXTREME_OBSERVARION <- function(x,sd_factor=2){
  which(x>mean(x)+sd_factor*sd(x) | x<mean(x)-sd_factor*sd(x))  
}

#-- import dei dati
ABSOLUTE_PATH <- "C:\\Users\\sbarberis\\Dropbox\\MODELLI STATISTICI"
d <- read.csv(paste0(ABSOLUTE_PATH,"\\F. Esercizi(22) copia\\2.Norm-Col copy(3)\\1.Norm-Col\\cpus.txt"),sep=" ")

#-- vettore di variabili numeriche presenti nei dati
VAR_NUMERIC <- names(d)[3:ncol(d)]

#-- print delle prime 6 righe del dataset
pander(head(d),big.mark=",")
```

> >

## STATISTICHE DESCRITTIVE

Si  presentano innanzitutto le statistiche descrittive.

> >

```{r,fig.width=6,echo=T,message=FALSE,results="asis"}
#-- R CODE
pander(summary(d[,VAR_NUMERIC]),big.mark=",") #-- statistiche descrittive
pander(cor(d[,VAR_NUMERIC]),big.mark=",") #-- matrice di correlazione
plot(d[,VAR_NUMERIC],pch=19,cex=.5) #-- scatter plot multivariato

par(mfrow=c(2,4))
for(i in VAR_NUMERIC){
  boxplot(d[,i],main=i,col="lightblue",ylab=i)
}
par(mfrow=c(2,4))
for(i in VAR_NUMERIC){
  hist(d[,i],main=i,col="lightblue",xlab=i,freq=F)
}
```

Si costruisce quindi un modello lineare in cui la variabile dipendente "perf" viene regredita rispetto alle variabili esplicative.


## REGRESSIONE

> >

```{r,fig.width=6,echo=T,message=FALSE,results="asis"}
#-- R CODE
mod1 <- lm(perf ~ syct + mmin + mmax + cach + chmin + chmax + estperf, d)
pander(summary(mod1),big.mark=",")
pander(anova(mod1),big.mark=",")
pander(white.test(mod1),big.mark=",")
pander(dwtest(mod1),big.mark=",")

pander(ols_vif_tol(mod1),big.mark=",")
pander(ols_eigen_cindex(mod1),big.mark=",")
```

I modello risulta significativo ma  solo la variabile "estperf" ha associato un parametro che cade nella regione di rifiuto per cui è respinta l’ipotesi nulla di non significatività.

Si esamina quindi la collinearità; come si può notare l’indice di tolleranza è molto piccolo e l’inflation indice è molto grande proprio per "estperf" l’unica variabile significativa, per cui la quota di varianza risulta altresì molto elevata per l’8^ autovalore. "estperf" risulta quindi multicollineare con le altre variabili e viene quindi eliminata. Si effettua una nuova regressione escludendo "estperf".

Si vede come come cambia radicalmente la situazione inerente la significatività delle variabili: "mmin", "mmax", "cach", "chmax" risultano significative. Inoltre nessuna delle variabili è ora collineare.

> >

```{r,fig.width=6,echo=T,message=FALSE,results="asis"}
#-- R CODE
mod1 <- lm(perf ~ syct + mmin + mmax + cach + chmin + chmax, d)
pander(summary(mod1),big.mark=",")
pander(anova(mod1),big.mark=",")
pander(white.test(mod1),big.mark=",")
pander(dwtest(mod1),big.mark=",")

pander(ols_vif_tol(mod1),big.mark=",")
pander(ols_eigen_cindex(mod1),big.mark=",")
```

Si analizza ora la normalità dei residui considerando il modello con le sole variabili significative "mmin", "mmax", "cach", "chmax". Si inizia studiando il valore degli indici di asimmetria e curtosi, la distribuzione dei residui e il box plot.

> >

```{r,fig.width=6,echo=T,message=FALSE,results="asis",warning =FALSE}
#-- R CODE

plot(mod1,which=2,pch=19)

hist(resid(mod1),col="lightblue",freq=F,xlab="Resid",main="")
lines(density(resid(mod1)),col=2,lwd=2)

pander(shapiro.test(resid(mod1))) 
pander(ks.test(resid(mod1),"pnorm")) 
```

La distribuzione dei residui sembra respingere l’ipotesi di normalità e tutti i test respingono l’ipotesi nulla di normalità.
Sia dal grafico del Q-Q plot che dal confronto dei quantili della distribuzione normale  teorica e osservata si vede la forte discrepanza tra tali distribuzioni. E’ una ulteriore prova della non normalità dei residui.



